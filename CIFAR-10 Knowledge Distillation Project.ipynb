{
 "cells": [
  {
   "cell_type": "raw",
   "id": "464fe2aa-1ad4-4571-91e8-f871053c86d1",
   "metadata": {},
   "source": [
    "Section 1: Imports and Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd8a183-94a2-4a59-8006-986010f9e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Set device\n",
    "if(torch.cuda.is_available()):      \n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU Not Avaliable\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40b98a19-ad27-44ae-8249-376d25e12d02",
   "metadata": {},
   "source": [
    "Section 2: Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdf2e472-1926-4696-b065-2b27a70d173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEACHER_EPOCHS = 15       # Epochs for teacher model\n",
    "STUDENT_EPOCHS = 20       # Epochs for student models\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "TEMPERATURE = 4.0\n",
    "ALPHA = 0.7"
   ]
  },
  {
   "cell_type": "raw",
   "id": "443d7bb7-fb17-4ece-9719-e36ff940059c",
   "metadata": {},
   "source": [
    "Section 3: Model Definitions (Teacher and Student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3265849a-154b-4b38-a710-3d5325f89137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher Model (ResNet-18 pre-trained on ImageNet)\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.model = torchvision.models.resnet18(weights='IMAGENET1K_V1')\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_features, 10)  # For CIFAR-10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# Student Model (small CNN)\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45e7d452-2f22-4891-b8a3-e1c1b2133348",
   "metadata": {},
   "source": [
    "Section 4: Data Loading (CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6653edde-df61-4dcd-9792-ca297ced872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [08:55<00:00, 318kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22352fbd-c662-44fe-a4f2-aa6ee8530316",
   "metadata": {},
   "source": [
    "Section 5: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baaf4bc-3036-4a96-bf2d-668c82d3c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "\n",
    "\n",
    "def evaluate_model(model, testloader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "def train_distilled_student(teacher, student, trainloader, optimizer, epoch, T, alpha):\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1} (Distill)\")\n",
    "    for inputs, labels in progress_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(inputs)\n",
    "\n",
    "        student_logits = student(inputs)\n",
    "\n",
    "        soft_loss = nn.KLDivLoss(reduction='batchmean')(\n",
    "            F.log_softmax(student_logits / T, dim=1),\n",
    "            F.softmax(teacher_logits / T, dim=1)\n",
    "        ) * (T * T)\n",
    "\n",
    "        hard_loss = F.cross_entropy(student_logits, labels)\n",
    "        total_loss = (alpha * soft_loss) + ((1 - alpha) * hard_loss)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += total_loss.item()\n",
    "        progress_bar.set_postfix(loss=running_loss / len(progress_bar))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7863892-8033-4b0e-b45d-34bbaf0c8c10",
   "metadata": {},
   "source": [
    "Section 6: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cf17c-4032-478e-b1ea-8dbf828a631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def measure_inference_speed(model, testloader):\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    num_images = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            start = time.time()\n",
    "            _ = model(inputs)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            total_time += (time.time() - start)\n",
    "            num_images += labels.size(0)\n",
    "    return total_time / num_images"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff0b5b5d-8a58-48d2-901e-1d39c3c95acb",
   "metadata": {},
   "source": [
    "Section 7: Phase 1 – Train Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090711fe-d883-4f25-992c-219d10ce1edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = TeacherModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "best_teacher_acc = 0.0\n",
    "best_teacher_state = None\n",
    "\n",
    "for epoch in range(TEACHER_EPOCHS):\n",
    "    train_model(teacher_model, trainloader, optimizer_teacher, criterion, epoch)\n",
    "    acc = evaluate_model(teacher_model, testloader)\n",
    "    print(f\"Teacher Accuracy after Epoch {epoch+1}: {acc:.2f}%\")\n",
    "    if acc > best_teacher_acc:\n",
    "        best_teacher_acc = acc\n",
    "        best_teacher_state = copy.deepcopy(teacher_model.state_dict())\n",
    "\n",
    "torch.save(best_teacher_state, \"teacher_best.pth\")\n",
    "teacher_model.load_state_dict(best_teacher_state)\n",
    "print(f\"✅ Final Teacher Accuracy: {best_teacher_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa00f254-3abc-47ec-853f-f4997e421535",
   "metadata": {},
   "source": [
    "Section 8: Phase 2 – Train Conventional Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0936f-637c-4bac-aebd-fc9f5f7f36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_conventional = StudentModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_student_conv = optim.Adam(student_conventional.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "best_student_conv_acc = 0.0\n",
    "\n",
    "for epoch in range(STUDENT_EPOCHS):\n",
    "    train_model(student_conventional, trainloader, optimizer_student_conv, criterion, epoch)\n",
    "    acc = evaluate_model(student_conventional, testloader)\n",
    "    print(f\"Conventional Student Accuracy after Epoch {epoch+1}: {acc:.2f}%\")\n",
    "    if acc > best_student_conv_acc:\n",
    "        best_student_conv_acc = acc\n",
    "\n",
    "torch.save(student_conventional.state_dict(), \"student_conventional_best.pth\")\n",
    "print(f\"✅ Final Conventional Student Accuracy: {best_student_conv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04d189c7-ef0c-4657-8068-708841c082fb",
   "metadata": {},
   "source": [
    "Section 9: Phase 3 – Train Distilled Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c517a7-7354-4b5d-a356-e1ac55786a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_distilled = StudentModel().to(device)\n",
    "optimizer_student_distill = optim.Adam(student_distilled.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "best_student_distill_acc = 0.0\n",
    "\n",
    "for epoch in range(STUDENT_EPOCHS):\n",
    "    train_distilled_student(\n",
    "        teacher=teacher_model,\n",
    "        student=student_distilled,\n",
    "        trainloader=trainloader,\n",
    "        optimizer=optimizer_student_distill,\n",
    "        epoch=epoch,\n",
    "        T=TEMPERATURE,\n",
    "        alpha=ALPHA\n",
    "    )\n",
    "    acc = evaluate_model(student_distilled, testloader)\n",
    "    print(f\"Distilled Student Accuracy after Epoch {epoch+1}: {acc:.2f}%\")\n",
    "    if acc > best_student_distill_acc:\n",
    "        best_student_distill_acc = acc\n",
    "\n",
    "torch.save(student_distilled.state_dict(), \"student_distilled_best.pth\")\n",
    "print(f\"✅ Final Distilled Student Accuracy: {best_student_distill_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e96a230-16d6-4865-8d1f-d57cf998ef01",
   "metadata": {},
   "source": [
    "Section 10: Final Comparison and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc70a0f-c9c2-44be-b858-756fa9cbc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_params = count_parameters(teacher_model)\n",
    "student_params = count_parameters(student_conventional)\n",
    "teacher_speed = measure_inference_speed(teacher_model, testloader)\n",
    "student_conv_speed = measure_inference_speed(student_conventional, testloader)\n",
    "student_distill_speed = measure_inference_speed(student_distilled, testloader)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{'Model':<25} | {'Accuracy (%)':<15} | {'Parameters':<15} | {'Avg. Inference (s/img)':<25}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'1. Teacher Model':<25} | {best_teacher_acc:<15.2f} | {teacher_params:<15,} | {teacher_speed:<25.8f}\")\n",
    "print(f\"{'2. Student (Conventional)':<25} | {best_student_conv_acc:<15.2f} | {student_params:<15,} | {student_conv_speed:<25.8f}\")\n",
    "print(f\"{'3. Student (Distilled)':<25} | {best_student_distill_acc:<15.2f} | {student_params:<15,} | {student_distill_speed:<25.8f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ✅ Success Criterion Check\n",
    "if best_student_distill_acc > best_student_conv_acc:\n",
    "    print(f\"\\n✅ Success: Distilled Student ({best_student_distill_acc:.2f}%) > Conventional ({best_student_conv_acc:.2f}%)\")\n",
    "else:\n",
    "    print(f\"\\n❌ Distilled Student ({best_student_distill_acc:.2f}%) did not outperform Conventional ({best_student_conv_acc:.2f}%)\")\n",
    "    print(\"Try tuning Alpha, Temperature, or learning rate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
